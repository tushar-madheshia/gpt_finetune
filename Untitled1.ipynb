{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
    "import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd10043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow:  2.3.0\n",
      "Transformers:  3.3.1\n",
      "Datasets:  1.2.0\n"
     ]
    }
   ],
   "source": [
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)\n",
    "\n",
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6599909",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "log_dir = f\"{data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{data_dir}/cache/t5.test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a5f25",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef9e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814f0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3731fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41. Subsequent calls will reuse this data.\n",
      "\n",
      "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n",
      "\n",
      "{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
      " 'context': Value(dtype='string', id=None),\n",
      " 'id': Value(dtype='string', id=None),\n",
      " 'question': Value(dtype='string', id=None),\n",
      " 'title': Value(dtype='string', id=None)}\"\n",
      " \n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('squad', split='train')\n",
    "valid_dataset = load_dataset('squad', split='validation')\n",
    "\n",
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e11e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
